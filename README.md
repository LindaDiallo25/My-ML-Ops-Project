# MLOps Project: Plant Classification (Dandelion vs Grass)

ğŸŒ¼ **Binary Image Classification with Full MLOps Pipeline**

## ğŸ“‹ Project Overview

This project implements a complete MLOps pipeline for classifying plant images (dandelions vs grass) using deep learning. It demonstrates industry best practices including:

- âœ… Data extraction & preprocessing
- âœ… CNN model training with TensorFlow/Keras
- âœ… Experiment tracking with MLflow
- âœ… Model storage in S3 (Minio)
- âœ… REST API with FastAPI
- âœ… React frontend WebApp
- âœ… Docker containerization
- âœ… Docker Compose orchestration
- ğŸ”„ CI/CD with GitHub Actions (optional)
- ğŸ”„ Airflow pipelines (optional)
- ğŸ“Š Monitoring (optional)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚â”€â”€â”€â”€â–¶â”‚   FastAPI    â”‚â”€â”€â”€â”€â–¶â”‚    Model    â”‚
â”‚  (React)    â”‚     â”‚   (8000)     â”‚     â”‚   (.keras)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                     â”‚
                            â–¼                     â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   MLflow     â”‚     â”‚   Minio S3  â”‚
                    â”‚   (5000)     â”‚     â”‚   (9000)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- 4GB+ RAM
- 5GB+ disk space

### 1ï¸âƒ£ Setup Python Environment

```bash
# Clone the repository
cd ML-Ops-project

# Create virtual environment (optional but recommended)
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Download & Prepare Data

```bash
# Download images from GitHub and clean them
python run_import_clean.py

# This will:
# - Download 200 dandelion + 200 grass images
# - Clean and resize to 256x256
# - Save to cleaned_images_for_model/
```

### 3ï¸âƒ£ Train Model with MLflow

```bash
# Start MLflow server (in separate terminal)
mlflow server --host 0.0.0.0 --port 5000

# Train the model
python train_with_mlflow.py

# Output:
# - dandelion_grass_cnn.keras (trained model)
# - training_history.png (accuracy/loss plots)
# - MLflow experiment logs
```

Visit **http://localhost:5000** to view MLflow UI with experiment tracking.

### 4ï¸âƒ£ Run with Docker Compose

```bash
# Build and start all services
docker-compose up --build

# Services will be available at:
# - Frontend:  http://localhost:3000
# - API:       http://localhost:8000
# - API Docs:  http://localhost:8000/docs
# - MLflow:    http://localhost:5000
# - Minio:     http://localhost:9001 (admin/minioadmin123)
```

### 5ï¸âƒ£ Test the API

```bash
# Health check
curl http://localhost:8000/health

# Test prediction with an image
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@path/to/your/image.jpg"

# Or visit http://localhost:8000/docs for Swagger UI
```

## ğŸ“ Project Structure

```
ML-Ops-project/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                    # FastAPI application
â”œâ”€â”€ Front/                         # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ cleaned_images_for_model/      # Processed training data
â”œâ”€â”€ image_data_from_repo/          # Raw downloaded images
â”œâ”€â”€ mlruns/                        # MLflow experiments
â”œâ”€â”€ run_import_clean.py            # Data download script
â”œâ”€â”€ run_train_model.py             # Basic training script
â”œâ”€â”€ train_with_mlflow.py           # Training with MLflow
â”œâ”€â”€ docker-compose.yml             # Services orchestration
â”œâ”€â”€ Dockerfile.api                 # API container
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸ¯ Model Details

- **Architecture**: CNN (3 Conv blocks + Dense layers)
- **Input**: 256x256 RGB images
- **Output**: Binary classification (sigmoid)
- **Training**: 15 epochs, batch size 32
- **Split**: 80% train, 20% validation
- **Framework**: TensorFlow/Keras 2.16.1

### Model Performance

- **Validation Accuracy**: 85%
- **Training Accuracy**: 92.4%
- **Training Time**: ~13 minutes (CPU)
- **Model Size**: 170MB

## ğŸ¨ WebApp Features

The React frontend provides:
- âœ¨ Drag & drop image upload
- ğŸ¯ Real-time prediction with confidence scores
- ğŸ“Š Animated progress bars
- ğŸ“± Responsive design (mobile & desktop)
- ğŸ”„ Reclassification support
- âŒ Graceful error handling with fallback

**Tech Stack**: React 18 + TypeScript + Vite + TailwindCSS + Framer Motion

## ğŸ”§ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information |
| `/health` | GET | Health check |
| `/predict` | POST | Image classification |
| `/model-info` | GET | Model details |
| `/docs` | GET | Swagger documentation |

## ğŸ³ Docker Images

### Build Individual Images

```bash
# API
docker build -t your-dockerhub-username/mlops-api:latest -f Dockerfile.api .

# Frontend
docker build -t your-dockerhub-username/mlops-frontend:latest ./Front

# Push to DockerHub
docker push your-dockerhub-username/mlops-api:latest
docker push your-dockerhub-username/mlops-frontend:latest
```

## ğŸ”¬ Development Workflow

### Local Development

```bash
# Run API locally
cd api
uvicorn main:app --reload --port 8000

# Run frontend locally
cd Front
npm install
npm run dev
```

### Testing

```bash
# Unit tests (TODO)
pytest tests/

# Integration tests (TODO)
pytest tests/integration/

# Load testing with Locust (TODO)
locust -f tests/load_test.py
```

## ğŸ“Š Monitoring & Logging

- **MLflow**: Track experiments, metrics, parameters
- **FastAPI logs**: Request/response logging
- **Docker logs**: `docker-compose logs -f api`

## ğŸ”„ CI/CD Pipeline (GitHub Actions)

```yaml
# .github/workflows/deploy.yml
# TODO: Add GitHub Actions workflow for:
# - Automated testing
# - Docker image building
# - Deployment to Kubernetes
```

## â˜¸ï¸ Kubernetes Deployment (Optional)

```bash
# TODO: Helm charts for:
# - API deployment
# - Frontend deployment
# - MLflow server
# - Minio storage
```

## ğŸ“ Learning Objectives Achieved

1. âœ… **Data Pipeline**: Automated download, cleaning, preprocessing
2. âœ… **Model Training**: CNN with TensorFlow/Keras (85% accuracy)
3. âœ… **Experiment Tracking**: MLflow integration with metrics logging
4. âœ… **Model Storage**: S3-compatible storage (Minio)
5. âœ… **API Development**: FastAPI with async support + Swagger docs
6. âœ… **Frontend WebApp**: React + TypeScript with real-time predictions
7. âœ… **Containerization**: Docker & Docker Compose orchestration
8. ğŸ”„ **Orchestration**: Airflow DAGs (to be implemented)
9. ğŸ”„ **CI/CD**: GitHub Actions (to be implemented)
10. ğŸ”„ **Monitoring**: Prometheus/Grafana (to be implemented)

## ğŸ“ TODO / Future Improvements

- [ ] Add Airflow DAGs for automated retraining
- [ ] Implement GitHub Actions CI/CD
- [ ] Add Prometheus + Grafana monitoring
- [ ] Deploy to Kubernetes
- [ ] Add unit & integration tests
- [ ] Implement feature store
- [ ] Add load testing with Locust
- [ ] Continuous training (CT) pipeline

## ğŸ‘¥ Team

- [Add team member names]

## ğŸ“§ Contact

For questions: prillard.martin@gmail.com

## ğŸ“„ License

MIT License

---

**Built with â¤ï¸ for MLOps learning**